# AI

Artificial intelligence, or AI, makes computers appear intelligent by simulating the cognitive abilities of humans. AI is a general field with a broad scope. It comprises computer vision, natural language processing, generative AI, machine learning, and deep learning.

An AI engineer is an "AI systems builder" typically using AI in a generative modality (though sometimes also for decisions and recommendations). Unlike data scientists, unstructured data of billions to trillions of tokens are used to train models. Application scope tends to be broader, require more computation, and longer training times. Development lifecycle starts with a use case, model selection, prompt engineering and embedding into an application. Application types include chaining, PEFT, RAG, and Agents.

Artificial intelligence (AI) simulates human cognition, while machine learning (ML) uses algorithms and requires feature engineering to learn from data.

## Definitions

- **large language model (LLM)**: A mathematical model trained on vast amounts of text data that can be used to predict what comes next for any piece of text. All possible next "words" are assigned a probability. Training involves adjusting the model's parameters, the probabilities of the next selected words, to minimize the difference between predicted and actual next words in the training data. The mathematical model can have hundreds of billions of parameters.
- **narrow AI**: AI that is designed to perform a specific task, typically a binary classifier, such as language translation, product recommendation, or fraud detection. It is not capable of generalizing its knowledge to other tasks.
- **machine learning**: A subset of AI that involves training algorithms to learn patterns from data and make predictions or decisions based on that data, e.g. predicting what a user will click on next, predicting banking and loan risk. Includes neural networks, deep and shallow. The data can be text or statistical.
- **deep learning**: A subset of machine learning that uses neural networks with many layers to learn complex patterns in large datasets, e.g. image and speech recognition.
- **natural language processing (NLP)**: A field of AI that focuses on the interaction between computers and humans through natural language, enabling machines to understand, interpret, and generate human language. **neural linguistic AI**: Text and meaning in text. Useful for Studocu. LLMs replacing NLP tasks.
- **computer vision**: A field of AI that enables machines to interpret and understand visual information from the world, such as images and videos, allowing them to recognize objects, faces, and scenes, and enabling auto-tagging of photos, for example.
- **expert system**: A computer system that uses knowledge and inference rules to solve specific problems within a particular domain, such as medical diagnosis or legal reasoning. Rules are often encoded in a knowledge base.
- **supervised learning**: A type of machine learning where the model is trained on labeled data, meaning the input data is paired with the correct output, allowing the model to learn the mapping between inputs and outputs.
- **unsupervised learning**: A type of machine learning where the model is trained on unlabeled data, meaning the input data does not have corresponding output labels, allowing the model to discover patterns and relationships in the data.
- **semi-supervised learning**: A type of machine learning that combines both labeled and unlabeled data for training, allowing the model to learn from a small amount of labeled data while leveraging the larger amount of unlabeled data.
- **reinforcement learning**: A type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize a reward signal, often used in robotics and game playing.

## Large language models (LLMs)

Large language models (LLMs) are a type of AI that can understand and generate human language. They are trained on vast amounts of text data and can perform various tasks, such as translation, summarization, question answering, and more. LLMs are often used in applications like chatbots, virtual assistants, and content generation.

Before LLMs appeared in 2022 we had different specific tools for summarization, and translation. LLMs are a single but multi-purpose tool. Now we are asking what else they can do. Write a novel? Make a scientific discovery?

Cool things happening now:

- Reasoning, a.k.a "true abstract reasoning": The original "LLM boom" was more related to what’s called “emerging capabilities”. The reasoning trend started later. It was also related to solving math and programming tasks.
- Agents: LLMs orchestrate to decide which strategies to use. Google had a paper that demonstrated a research assistant multi-agentive tool.
- Open-endedness: It has the potential to adapt to solve many different tasks. You don't need to tune it to play a particular game. It can learn.

### Ways of using LLMs as a product

- **ChatGPT**: Very good if you want something quick, but usage gets quickly repetitive. The file is fixed, and static and gets out of date.
- **NotebookLM**: Was the first to demo RAG, it references the text in the source. Works well for FAQs, documentation. It is sort of up to date, because you can manually update the source and resume the session.
- **Fine-tuning**: An example of this process involves taking a model, like one on open AI, uploading a JSONL file, setting up prompts with the desired and not desired output (the kinds of answers it should give), and running the fint-tuning process. This is best for specific tasks or domains, like customer support or legal advice. Medium effort, but can be expensive, e.g. 100 EUR per fine-tuning run. The end result is that you can train models to be more accurate at specific tasks, such as generating code, having a specific personality, or generating images in a specific style.
- **retrieval augmented generation (RAG)**: An example of NotebookLM, which is a retrieval augmented generation model. It can access external data sources to provide more accurate and up-to-date information. Very powerful but expensive (20 EUR month per user), deploy DB, search engine, plus compute to convert text in vectors.
- **model context protocol (MCP)**: An example of this is giving GitHub Copilot permission to access APIs and do additional things, like post to Slack, or create a pull request.

### Ways of using LLMs technically

1. manual/UI: You interact with the LLM through a user interface, like ChatGPT. This is best for personal use. Low effort. Dump in a file attach it, and start prompting.
2. API: You use the LLM through an API, like OpenAI's API. This is best for integrating LLMs into applications or services. Medium effort. A good sweet spot for startups.
3. Cloud infrastructure: You deploy the LLM on your own infrastructure or use a cloud provider, like using Hugging Face's Transformers library. This is best for large-scale applications or when you need more control over the model. High effort. Google is quite rate limited. AWS is good since it offers access to anthropic.

TL;DR Calling APIs are not the only way to do things. Some things have privacy limitations so can't just make API calls or can only call to entities in the same geographical space.

### Impact of LLM size

The size of an LLM impacts its performance and capabilities. Larger models tend to have more parameters, which allows them to learn more complex patterns and relationships in the data. However, they require more computational resources and memory, and are more expensive to train and deploy and have much greater environmental impacts. By contrast smaller models are faster, cheaper but may not perform as well on certain tasks.

- **edge AI**: Something that Cloudflare is pushing for. It involves running AI algorithms directly on devices at the "edge" of a network, rather than relying on cloud servers. This means processing data locally, close to the user. The typical budge is 100-1GB
- **tiny AI**: A term used to describe small, efficient AI models that can run on low-power devices, such as smartphones, IoT devices or in browser extensions. The typical budget is 1-100MB.
- **nano AI**: A term used to describe extremely small AI models that can run on very low-power devices, such as microcontrollers or embedded systems. The typical budget is <1MB.

With smaller modesl you can build privacy friendly or offline applications. You can also have a hybrid application that only callas external APIS with extra horsepower is necessary. Applications of small AI models include:

- image classification
- speech recognition
- text classification
- anomaly detection
- sentiment analysis

### LLM Project pipeline

1. LLM Dataset Generation
1. PyTorch Training (Python)
1. Weight Quantization (Int8)
1. TypeScript Code Generation
1. Browser Extension (WXT)
1. Web Worker Inference

## Machine learning (ML)

## Language support

### JavaScript

- [TensorFlow.js](https://www.tensorflow.org/js): The TensorFlow ecosystem is a suite of tools for training models, a repository of existing models (vision, body, text, audio) and technology for deploying models. It provides full neural network ops and WebGL/WebGPU back-ends.
- [ml5.js](https://ml5js.org/): "ml5.js aims to make machine learning approachable for a broad audience of artists, creative coders, and students. The library provides access to machine learning algorithms and models in the browser, building on top of TensorFlow.js"
- [ONNX Runtime Web](https://onnxruntime.ai/docs/tutorials/web/): ONNX Runtime Web is a JavaScript library that enables running ONNX (Open Neural Network Exchange) machine learning models directly in web browsers with WebAssembly and WebGL. It supports models trained in frameworks like PyTorch and TensorFlow, converted to ONNX format.
- [WebDNN](https://mil-tokyo.github.io/webdnn/)
- [MediaPipe Tasks](https://ai.google.dev/edge/mediapipe/solutions/tasks)
- [Web Neural Network API](https://www.w3.org/TR/webnn/)

### Python / Mojo

TK.

## Resources

- OpenRouter.ai LLMs rankings: <https://openrouter.ai/rankings>
- LLM Tools: <https://ossinsight.io/collections/llm-tools/>
- LLM Dev Tools: <https://ossinsight.io/collections/llm-dev-tools/>
- Vector Databases: <https://ossinsight.io/collections/vector-search-engine/>
- Articial Intelligence: <https://ossinsight.io/collections/artificial-intelligence/>
- Machine Learning in Rust: <https://ossinsight.io/collections/ml-in-rust>
- ChatGPT Apps: <https://ossinsight.io/collections/chat-gpt-apps/>
- ChatGPT Alternatives: <https://ossinsight.io/collections/chat-gpt-alternatives/>
- Machine Learning OPs Tools: <https://ossinsight.io/collections/ml-ops-tools/>
- Best GPUs latest rankings/benchmarkings & average price (for LLMs usage): <https://benchmarks.ul.com/compare/best-gpus>
